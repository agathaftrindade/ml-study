{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf6f433-965f-4590-867f-a7e2d1555b6a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlcroissant\n",
      "  Downloading mlcroissant-1.0.9-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting absl-py (from mlcroissant)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting etils>=1.7.0 (from etils[epath]>=1.7.0->mlcroissant)\n",
      "  Downloading etils-1.9.4-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting jsonpath-rw (from mlcroissant)\n",
      "  Downloading jsonpath-rw-1.4.0.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from mlcroissant) (3.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from mlcroissant) (2.2.3)\n",
      "Collecting pandas-stubs (from mlcroissant)\n",
      "  Downloading pandas_stubs-2.2.3.241009-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.11/site-packages (from mlcroissant) (2.9.0)\n",
      "Collecting rdflib (from mlcroissant)\n",
      "  Downloading rdflib-7.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from mlcroissant) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from mlcroissant) (4.66.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from etils[epath]>=1.7.0->mlcroissant) (2024.9.0)\n",
      "Requirement already satisfied: importlib_resources in /opt/conda/lib/python3.11/site-packages (from etils[epath]>=1.7.0->mlcroissant) (6.4.5)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.11/site-packages (from etils[epath]>=1.7.0->mlcroissant) (4.12.2)\n",
      "Requirement already satisfied: zipp in /opt/conda/lib/python3.11/site-packages (from etils[epath]>=1.7.0->mlcroissant) (3.20.2)\n",
      "Collecting ply (from jsonpath-rw->mlcroissant)\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from jsonpath-rw->mlcroissant) (5.1.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from jsonpath-rw->mlcroissant) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas->mlcroissant) (2.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->mlcroissant) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->mlcroissant) (2024.2)\n",
      "Collecting types-pytz>=2022.1.1 (from pandas-stubs->mlcroissant)\n",
      "  Downloading types_pytz-2024.2.0.20241003-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting isodate<0.7.0,>=0.6.0 (from rdflib->mlcroissant)\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from rdflib->mlcroissant) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->mlcroissant) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->mlcroissant) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->mlcroissant) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->mlcroissant) (2024.8.30)\n",
      "Downloading mlcroissant-1.0.9-py2.py3-none-any.whl (135 kB)\n",
      "Downloading etils-1.9.4-py3-none-any.whl (164 kB)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading pandas_stubs-2.2.3.241009-py3-none-any.whl (157 kB)\n",
      "Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Downloading types_pytz-2024.2.0.20241003-py3-none-any.whl (5.2 kB)\n",
      "Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "Building wheels for collected packages: jsonpath-rw\n",
      "  Building wheel for jsonpath-rw (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jsonpath-rw: filename=jsonpath_rw-1.4.0-py3-none-any.whl size=15130 sha256=9ff1e9d73427e22987ef60c23042a191720b2aeb79fcdf7c4615a92077251a36\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/53/cf/51/a4ea10224b7fdb523e18e2033cadf2a8657517d1f95f3f5413\n",
      "Successfully built jsonpath-rw\n",
      "Installing collected packages: ply, types-pytz, jsonpath-rw, isodate, etils, absl-py, rdflib, pandas-stubs, mlcroissant\n",
      "Successfully installed absl-py-2.1.0 etils-1.9.4 isodate-0.6.1 jsonpath-rw-1.4.0 mlcroissant-1.0.9 pandas-stubs-2.2.3.241009 ply-3.11 rdflib-7.0.0 types-pytz-2024.2.0.20241003\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlcroissant\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "748f6a0f-0b23-44a4-9f5d-00a7d2eaa33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlcroissant as mlc\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4578098-edb1-489b-b345-fa31775462f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:WARNING: The JSON-LD `@context` is not standard. Refer to the official @context (e.g., from the example datasets in https://github.com/mlcommons/croissant/tree/main/datasets/1.0). The different keys are: {'examples', 'rai'}\n",
      "WARNING:absl:Found the following 1 warning(s) during the validation:\n",
      "  -  [Metadata(Spam email Dataset)] Property \"http://mlcommons.org/croissant/citeAs\" is recommended, but does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RecordSet(uuid=\"emails.csv\")]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>Subject: re : research and development charges...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>Subject: re : receipts from visit  jim ,  than...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>Subject: re : enron case study update  wow ! a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>Subject: re : interest  david ,  please , call...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Subject: news : aurora 5 . 2 update  aurora ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  is_spam\n",
       "0     Subject: naturally irresistible your corporate...        1\n",
       "1     Subject: the stock trading gunslinger  fanny i...        1\n",
       "2     Subject: unbelievable new homes made easy  im ...        1\n",
       "3     Subject: 4 color printing special  request add...        1\n",
       "4     Subject: do not have money , get software cds ...        1\n",
       "...                                                 ...      ...\n",
       "5723  Subject: re : research and development charges...        0\n",
       "5724  Subject: re : receipts from visit  jim ,  than...        0\n",
       "5725  Subject: re : enron case study update  wow ! a...        0\n",
       "5726  Subject: re : interest  david ,  please , call...        0\n",
       "5727  Subject: news : aurora 5 . 2 update  aurora ve...        0\n",
       "\n",
       "[5728 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fetch the Croissant JSON-LD\n",
    "croissant_dataset = mlc.Dataset('https://www.kaggle.com/datasets/jackksoncsie/spam-email-dataset/croissant/download')\n",
    "\n",
    "# Check what record sets are in the dataset\n",
    "record_sets = croissant_dataset.metadata.record_sets\n",
    "print(record_sets)\n",
    "\n",
    "# Fetch the records and put them in a DataFrame\n",
    "df = pd.DataFrame(croissant_dataset.records(record_set=record_sets[0].uuid))\n",
    "df = df.rename(columns = {\n",
    "    'emails.csv/text': 'body',\n",
    "    'emails.csv/spam': 'is_spam'\n",
    "})\n",
    "df['body'] = df['body'].apply(lambda x: x.decode())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8cefaa15-242a-4ea8-bc14-868ff68c084b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8720 2736\n"
     ]
    }
   ],
   "source": [
    "ham_count = df[df.is_spam == 0].size\n",
    "spam_count = df[df.is_spam == 1].size\n",
    "\n",
    "print(ham_count, spam_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5ccb1046-54b3-47f3-b2f1-6dbc7c056409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(t):\n",
    "    t = str.lower(t[8:])\n",
    "\n",
    "    # filter non ascii characters\n",
    "    t = ''.join(filter(lambda x: x in string.ascii_letters + ' ', t))\n",
    "\n",
    "    # remove small words\n",
    "    t = ' '.join(filter(lambda x: len(x) > 2, t.split()))    \n",
    "    return t\n",
    "\n",
    "def get_word_set(X):\n",
    "    unique_words = {w for l in X for w in l.split()} \n",
    "    return unique_words\n",
    "\n",
    "def count_words(text, known_words):\n",
    "    t = clean_text(text)\n",
    "    bag_of_words = {}\n",
    "    for w in t.split():\n",
    "        if not w in known_words:\n",
    "            continue\n",
    "\n",
    "        if w not in bag_of_words:\n",
    "            bag_of_words[w] = 0\n",
    "            \n",
    "        bag_of_words[w] += 1\n",
    "    return bag_of_words\n",
    "\n",
    "def count_words_list(texts, known_words):\n",
    "    text_words = [w for row in texts for w in row.split()]\n",
    "    return count_words(' '.join(text_words), known_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "fb8619c6-3bef-4628-9374-8146acc57fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       naturally irresistible your corporate identity...\n",
       "1       the stock trading gunslinger fanny merrill but...\n",
       "2       unbelievable new homes made easy wanting show ...\n",
       "3       color printing special request additional info...\n",
       "4       not have money get software cds from here soft...\n",
       "                              ...                        \n",
       "5723    research and development charges gpg here forw...\n",
       "5724    receipts from visit jim thanks again for the i...\n",
       "5725    enron case study update wow all the same day t...\n",
       "5726    interest david please call shirley crenshaw as...\n",
       "5727    news aurora update aurora version the fastest ...\n",
       "Name: clean_body, Length: 5728, dtype: object"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_body'] = df.body.apply(clean_text)\n",
    "df.clean_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cb75fff0-d0b2-4638-8c9b-395cd99839a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subject: news : aurora 5 . 2 update  aurora version 5 . 2  - the fastest model just got faster -  epis announces the release of aurora , version 5 . 2  aurora the electric market price forecasting tool is already  legendary for power and speed . we \\' ve combined a powerful chronological  dispatch model with the capability to simulate the market from 1  day to 25 + years . add to that a risk analysis section , powered by user  selectable monte carlo & / or latin hypercube modeling , enough  portfolio analysis power to please the toughest critic , & inputs and  outputs from standard excel & access tables and you \\' ve got one of most  powerful tools in the market .  just a few months ago we expanded our emissions modeling  capabilities , added our quarterly database update , increased the speed  of the entire model , and made  but that wasn \\' t enough .  we \\' ve done it again . some of the operations that we \\' ve  included . . .  two new reporting enhancements .  the first is marginal reporting  for fuels , resources and groups of resources .  the second is the ability to  display resource stack information in graphical and dispatch order form .  other enhancements include dual fuel modeling , improved  transmission modeling , greater access to hourly results , and the ability  to model monthly emission rates . moreover , the databases for  central and eastern , texas , and western markets have been updated to use  the new modeling capabilities .  we continue to make aurora easier to use . this version enhances  user control over modeling , editing inputs , and viewing of aurora  output . clients desiring to exploit the power of aurora now have  greater control over the inputs and outputs through vb scripting in  aurora . the new \" update data \" capability provides a means to  universally change any data element .  attached is more information on the fastest and most flexible  tool of its kind .  for additional information , please visit our website ( www . epis . com ) or  contact our sales department at ( 503 ) 722 - 2023 . ask about our special  7 - day demo !  v . todd wheeler  sales manager  epis , inc .  ( 503 ) 722 - 2023 tel .  ( 503 ) 722 - 7130 fax  www . epis . com  todd @ epis . com  > >  - what \\' s new - version 5 . 2 information . doc  - technical information aurora v 5 - 2 . doc'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[-1].body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "31fbc633-b295-4e11-adf5-a04d4d5068f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "{'emissions', 'enhances', 'outputs', 'scripting', 'toughest', 'carlo', 'latin', 'emission', 'stack', 'marginal', 'legendary', 'aurora', 'hourly', 'epis', 'exploit', 'selectable', 'desiring', 'wheeler', 'monte', 'simulate', 'hypercube', 'chronological', 'critic'}\n"
     ]
    }
   ],
   "source": [
    "class BayesFilter():\n",
    "    def __init__(self, c_threshold = 100):\n",
    "        self.c_threshold = c_threshold\n",
    "        \n",
    "    def train(self, train_data):\n",
    "        known_words = get_word_set(train_data.clean_body.to_list())\n",
    "\n",
    "        ham_data = train_data[train_data.is_spam == 0]\n",
    "        X_ham = ham_data.clean_body\n",
    "\n",
    "        spam_data = train_data[train_data.is_spam == 1]\n",
    "        X_spam = spam_data.clean_body\n",
    "\n",
    "        self.ham_wbag = count_words_list(X_ham, known_words)\n",
    "        self.spam_wbag = count_words_list(X_spam, known_words)\n",
    "        \n",
    "        self.prob_spam = spam_data.size / (spam_data.size + ham_data.size)\n",
    "        \n",
    "    def predict(self, body):\n",
    "        body = clean_text(body)\n",
    "        body_wordset = get_word_set([body])\n",
    "        \n",
    "        px_ham = body_wordset - set(self.ham_wbag.keys())\n",
    "        print(px_ham)\n",
    "\n",
    "        px_spam = body_wordset - set(self.spam_wbag.keys())\n",
    "        print(px_spam)\n",
    "        \n",
    "        # l2 = self.\n",
    "        # l2 = self.prob_spam / (1 - self.prob_ham)\n",
    "        pass\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'BayesFilter(c_threshold: {self.c_threshold}, prob_spam: {self.prob_spam})'\n",
    "f = BayesFilter()\n",
    "f.train(df)\n",
    "f.predict(df.body.iloc[-1])\n",
    "# train_data = df[df.is_spam == 0]\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5634ac-7219-47ea-a4eb-a2b131c1a25d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
